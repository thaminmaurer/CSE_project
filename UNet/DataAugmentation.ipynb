{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78c04cbf-40c4-4c10-9323-e460ea95aeca",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c0446f-458d-40d4-a753-cfccb1d9e0cf",
   "metadata": {},
   "source": [
    "We need to have our folder with the base training and another folder where we will store the transormed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5ebe275-8368-4cec-902d-53b0adda4d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "from tqdm import tqdm\n",
    "from helpers import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67a584c6-2257-4376-84fe-373a531c0681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: C:\\Users\\thami\\OneDrive\\Dokumente\\EPFL\\Master\\Projet_de_Semestre\\CSE_Project\\unet-road-segmentation\n"
     ]
    }
   ],
   "source": [
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Print the current directory\n",
    "print(\"Current Directory:\", current_directory)\n",
    "\n",
    "BASE_TRAINING = '../uavid_v1.5_official_release_image/all_images_combined/'\n",
    "BASE_TRAIN_IMAGES = BASE_TRAINING + 'Images/'\n",
    "BASE_TRAIN_GROUNDTRUTH = BASE_TRAINING + 'binary_labels/'\n",
    "\n",
    "TRAINING = '../uavid_v1.5_official_release_image/all_images_combined_augmented/'\n",
    "TRAIN_IMAGES = TRAINING + 'Images/'\n",
    "TRAIN_GROUNDTRUTH = TRAINING + 'binary_labels/'\n",
    "\n",
    "# BASE_TRAINING = 'base_training/'\n",
    "# BASE_TRAIN_IMAGES = BASE_TRAINING + 'images/'\n",
    "# BASE_TRAIN_GROUNDTRUTH = BASE_TRAINING + 'groundtruth/'\n",
    "\n",
    "# TRAINING = 'training/'\n",
    "# TRAIN_IMAGES = TRAINING + 'images/'\n",
    "# TRAIN_GROUNDTRUTH = TRAINING + 'groundtruth/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a258b2b-15ea-4416-b6d2-ebf0bab14616",
   "metadata": {},
   "source": [
    "### Add 90, 180 and 270º rotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "199a984c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run helpers.py # To refresh the helpers file if there is an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "873d625c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/270 [00:00<?, ?it/s]C:\\Users\\thami\\OneDrive\\Dokumente\\EPFL\\Master\\Projet_de_Semestre\\CSE_Project\\unet-road-segmentation\\helpers.py:106: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(img_rotations)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 270/270 [07:11<00:00,  1.60s/it]\n"
     ]
    }
   ],
   "source": [
    "# Generate the rotated images\n",
    "for img_name in tqdm(os.listdir(BASE_TRAIN_IMAGES), total=len(os.listdir(BASE_TRAIN_IMAGES))):\n",
    "    \n",
    "    # Skip directories\n",
    "    if os.path.isdir(img_name):\n",
    "        continue\n",
    "    \n",
    "    image = cv.imread(BASE_TRAIN_IMAGES + img_name)\n",
    "    img_train_rotations = get_rotations_0_90_180_270(image)\n",
    "    for i, rotated_image in enumerate(img_train_rotations[1:]): # Avoid original image\n",
    "        cv.imwrite(os.path.join(TRAIN_IMAGES , img_name[:-4] + '_rotation_' + str((i+1)*90) + \".png\"), rotated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28661496-3db7-4a72-89e1-75feb80874f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 270/270 [00:28<00:00,  9.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# Generate the rotated groundtruths\n",
    "for img_name in tqdm(os.listdir(BASE_TRAIN_GROUNDTRUTH), total=len(os.listdir(BASE_TRAIN_GROUNDTRUTH))):\n",
    "    \n",
    "    # Skip directories\n",
    "    if os.path.isdir(img_name):\n",
    "        continue\n",
    "    \n",
    "    image = cv.imread(BASE_TRAIN_GROUNDTRUTH + img_name)\n",
    "    image = image[:, :, 0]\n",
    "    img_train_rotations = get_rotations_0_90_180_270(image)\n",
    "    for i, rotated_image in enumerate(img_train_rotations[1:]): # Avoid original image\n",
    "        cv.imwrite(os.path.join(TRAIN_GROUNDTRUTH , img_name[:-4] + '_rotation_' + str((i+1)*90) + \".png\"), rotated_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788a5510",
   "metadata": {},
   "source": [
    "### Add randomly rotated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ea3a045",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run helpers.py # To refresh the helpers file if there is an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7ee15ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick how many rotations you want per image, \n",
    "# if you want more rotations delete all images and change the number here to avoid name conflicts\n",
    "ROTATIONS_PER_IMAGE = 3\n",
    "degrees = []\n",
    "centers = []\n",
    "for i in range(ROTATIONS_PER_IMAGE*len(os.listdir(BASE_TRAIN_IMAGES))):\n",
    "    degrees.append(random.randint(0, 90)) # random rotation of degree between 0 and 90\n",
    "    centers.append((random.randint(40, 60), random.randint(40, 60))) # random center between 40% and 60% of image width & length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13983811",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 270/270 [06:00<00:00,  1.33s/it]\n"
     ]
    }
   ],
   "source": [
    "# Generate the rotated images\n",
    "index = 0\n",
    "for img_name in tqdm(os.listdir(BASE_TRAIN_IMAGES), total=len(os.listdir(BASE_TRAIN_IMAGES))):\n",
    "    \n",
    "    # Skip directories\n",
    "    if os.path.isdir(img_name):\n",
    "        continue\n",
    "    \n",
    "    image = cv.imread(BASE_TRAIN_IMAGES + img_name)\n",
    "    for i in range(ROTATIONS_PER_IMAGE):\n",
    "        random_rotation = get_rotation_deg_n(image, degrees[index], centers[index])\n",
    "        cv.imwrite(os.path.join(TRAIN_IMAGES , img_name[:-4] + '_random_rotation_' + str(i) + \".png\"), random_rotation)\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e004e2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 270/270 [00:36<00:00,  7.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# Generate the rotated groundtruths\n",
    "index = 0\n",
    "for img_name in tqdm(os.listdir(BASE_TRAIN_GROUNDTRUTH), total=len(os.listdir(BASE_TRAIN_GROUNDTRUTH))):\n",
    "    \n",
    "    # Skip directories\n",
    "    if os.path.isdir(img_name):\n",
    "        continue\n",
    "    \n",
    "    image = cv.imread(BASE_TRAIN_GROUNDTRUTH + img_name)\n",
    "    image = image[:, :, 0]\n",
    "    for i in range(ROTATIONS_PER_IMAGE):\n",
    "        random_rotation = get_rotation_deg_n(image, degrees[index], centers[index])\n",
    "        cv.imwrite(os.path.join(TRAIN_GROUNDTRUTH , img_name[:-4] + '_random_rotation_' + str(i) + \".png\"), random_rotation)\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f66a0b-769b-4a8c-b329-19b16b430130",
   "metadata": {},
   "source": [
    "### Add horizontally and vertically flipped images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f68d97b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run helpers.py # To refresh the helpers file if there is an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "733957db",
   "metadata": {},
   "outputs": [],
   "source": [
    "flip_type = ['x', 'y'] # Types of wanted flips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f43ae38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 270/270 [05:02<00:00,  1.12s/it]\n"
     ]
    }
   ],
   "source": [
    "# Generate the flipped images\n",
    "for img_name in tqdm(os.listdir(BASE_TRAIN_IMAGES), total=len(os.listdir(BASE_TRAIN_IMAGES))):\n",
    "    \n",
    "    # Skip directories\n",
    "    if os.path.isdir(img_name):\n",
    "        continue\n",
    "    \n",
    "    image = cv.imread(BASE_TRAIN_IMAGES + img_name)\n",
    "    img_train_flips = get_flipped_images(image)\n",
    "    for i, flipped_image in enumerate(img_train_flips[1:]): # Avoid original image\n",
    "        cv.imwrite(os.path.join(TRAIN_IMAGES , img_name[:-4] + '_flipped_' + flip_type[i] + \".png\"), flipped_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "012d89cd-663d-4ef3-a1e4-72041f76426e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 270/270 [00:23<00:00, 11.62it/s]\n"
     ]
    }
   ],
   "source": [
    "# Generate the flipped groundtruths\n",
    "for img_name in tqdm(os.listdir(BASE_TRAIN_GROUNDTRUTH), total=len(os.listdir(BASE_TRAIN_GROUNDTRUTH))):\n",
    "    \n",
    "    # Skip directories\n",
    "    if os.path.isdir(img_name):\n",
    "        continue\n",
    "    \n",
    "    image = cv.imread(BASE_TRAIN_GROUNDTRUTH + img_name)\n",
    "    image = image[:, :, 0]\n",
    "    img_train_flips = get_flipped_images(image)\n",
    "    for i, flipped_image in enumerate(img_train_flips[1:]): # Avoid original image\n",
    "        cv.imwrite(os.path.join(TRAIN_GROUNDTRUTH , img_name[:-4] + '_flipped_' + flip_type[i] + \".png\"), flipped_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a410d568-bf84-465f-8b07-dfd7db2489b6",
   "metadata": {},
   "source": [
    "### Add gaussian noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50812d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run helpers.py # To refresh the helpers file if there is an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40bf44c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance of the gaussian noise\n",
    "VARIANCE = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8a0f7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:06<00:00, 16.43it/s]\n"
     ]
    }
   ],
   "source": [
    "# Generate the noisy images\n",
    "for img_name in tqdm(os.listdir(BASE_TRAIN_IMAGES), total=len(os.listdir(BASE_TRAIN_IMAGES))):\n",
    "    image = cv.imread(BASE_TRAIN_IMAGES + img_name)\n",
    "    img_train_noise = noisy('gauss', image, var=VARIANCE)\n",
    "    cv.imwrite(os.path.join(TRAIN_IMAGES , img_name[:-4] + '_noise_' + 'gauss_var_' + str(VARIANCE) + \".png\"), img_train_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b15b91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 100.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# Copy the groundtruths as they do not change\n",
    "for img_name in tqdm(os.listdir(BASE_TRAIN_GROUNDTRUTH), total=len(os.listdir(BASE_TRAIN_GROUNDTRUTH))):\n",
    "    image = cv.imread(BASE_TRAIN_GROUNDTRUTH + img_name)\n",
    "    image = image[:, :, 0]\n",
    "    cv.imwrite(os.path.join(TRAIN_GROUNDTRUTH , img_name[:-4] + '_noise_' + 'gauss_var_' + str(VARIANCE) + \".png\"), image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc9ddbc",
   "metadata": {},
   "source": [
    "### Add salt and pepper noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "efbb96ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run helpers.py # To refresh the helpers file if there is an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7476d367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratio of pixels to be corrupted\n",
    "CORRUPTION_RATIO = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a2b3cc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:05<00:00, 19.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# Generate the noisy images\n",
    "for img_name in tqdm(os.listdir(BASE_TRAIN_IMAGES), total=len(os.listdir(BASE_TRAIN_IMAGES))):\n",
    "    image = cv.imread(BASE_TRAIN_IMAGES + img_name)\n",
    "    img_train_noise = noisy('s&p', image, var=VARIANCE)\n",
    "    cv.imwrite(os.path.join(TRAIN_IMAGES , img_name[:-4] + '_noise_' + 's&p_corrupt_' + str(CORRUPTION_RATIO) + \".png\"), img_train_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "786b4160",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 108.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# Copy the groundtruths as they do not change\n",
    "for img_name in tqdm(os.listdir(BASE_TRAIN_GROUNDTRUTH), total=len(os.listdir(BASE_TRAIN_GROUNDTRUTH))):\n",
    "    image = cv.imread(BASE_TRAIN_GROUNDTRUTH + img_name)\n",
    "    image = image[:, :, 0]\n",
    "    cv.imwrite(os.path.join(TRAIN_GROUNDTRUTH , img_name[:-4] + '_noise_' + 's&p_corrupt_' + str(CORRUPTION_RATIO) + \".png\"), image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9fd220-e3e8-40cd-9443-28ef836ddfcc",
   "metadata": {},
   "source": [
    "### Add original images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6e69a02e-ce61-4d9f-acf0-4cec28bab313",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 24.06it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get the original images\n",
    "for img_name in tqdm(os.listdir(BASE_TRAIN_IMAGES), total=len(os.listdir(BASE_TRAIN_IMAGES))):\n",
    "    image = cv.imread(BASE_TRAIN_IMAGES + img_name)\n",
    "    cv.imwrite(os.path.join(TRAIN_IMAGES + img_name), image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3372183e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 108.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get the original groundtruths\n",
    "for img_name in tqdm(os.listdir(BASE_TRAIN_GROUNDTRUTH), total=len(os.listdir(BASE_TRAIN_GROUNDTRUTH))):\n",
    "    image = cv.imread(BASE_TRAIN_GROUNDTRUTH + img_name)\n",
    "    image = image[:, :, 0]\n",
    "    cv.imwrite(os.path.join(TRAIN_GROUNDTRUTH + img_name), image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9779dc52",
   "metadata": {},
   "source": [
    "### Delete images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "573ecacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/976 [00:00<?, ?it/s]100%|██████████| 976/976 [00:03<00:00, 291.57it/s]\n",
      "100%|██████████| 1400/1400 [00:04<00:00, 344.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# Remove all images and groundtruths in the folders, do this whenever you want to try new augmentation sets\n",
    "for filename in tqdm(os.listdir(TRAIN_IMAGES),total=len(os.listdir(TRAIN_IMAGES))):\n",
    "    file_path = os.path.join(TRAIN_IMAGES, filename)\n",
    "    try:\n",
    "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "            os.unlink(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "    except Exception as e:\n",
    "        print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "        \n",
    "for filename in tqdm(os.listdir(TRAIN_GROUNDTRUTH),total=len(os.listdir(TRAIN_GROUNDTRUTH))):\n",
    "    file_path = os.path.join(TRAIN_GROUNDTRUTH, filename)\n",
    "    try:\n",
    "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "            os.unlink(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "    except Exception as e:\n",
    "        print('Failed to delete %s. Reason: %s' % (file_path, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90676756",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
